{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-17T23:52:20.933660Z",
     "start_time": "2023-10-17T23:52:15.805483Z"
    }
   },
   "outputs": [],
   "source": [
    "/**\n",
    " * Helper function to wrap output in visual line breaks\n",
    " *\n",
    " * @param title title of the specific section\n",
    " * @param separator string to use as the line break string\n",
    " * @param n length of the line break\n",
    " * @param block block of code to run in between the line breaks\n",
    " */\n",
    "fun wrap(title: String, separator: String = \"-\", n: Int = 20, block: () -> Unit): Unit {\n",
    "    println(title)\n",
    "    repeat(n) { print(separator) }\n",
    "    println()\n",
    "    block()\n",
    "    repeat(n) { print(separator) }\n",
    "    println()\n",
    "}\n",
    "\n",
    "/**\n",
    " * Enum for differentiating the token type\n",
    " *\n",
    " * ID: identifiers\n",
    " * EQ: equal size\n",
    " * OR: pipe\n",
    " * AC: character that is inside the alphabet\n",
    " * AS: accepting state\n",
    " * NL: newline\n",
    " */\n",
    "enum class TokenType {\n",
    "    ID,\n",
    "    EQ,\n",
    "    OR,\n",
    "    AC,\n",
    "    AS,\n",
    "    NL,\n",
    "}\n",
    "\n",
    "/**\n",
    " * Class for storing the tokens in the lexer\n",
    " *\n",
    " * @property value the lexeme of the token\n",
    " * @property type the type of the token, see [TokenType]\n",
    " */\n",
    "data class Token(val value: String, val type: TokenType)\n",
    "\n",
    "/**\n",
    " * Sealed interface for the Grammar Abstract Syntax Tree (AST) Structure\n",
    " *\n",
    " * @property next the next node in the AST (more of a vine instead of a tree)\n",
    " */\n",
    "sealed interface Grammar {\n",
    "    var next: Grammar?\n",
    "}\n",
    "\n",
    "/**\n",
    " * AST node for an identifier\n",
    " *\n",
    " * @property name the name of the identifier\n",
    " */\n",
    "data class Ident(val name: String, override var next: Grammar? = null) : Grammar {\n",
    "    override fun toString(): String = \"$name${next?.toString() ?: \"\"}\"\n",
    "}\n",
    "\n",
    "/**\n",
    " * AST node for an alphabetic character\n",
    " *\n",
    " * @property character the character this node represents, stored as a string for easier conversions\n",
    " */\n",
    "data class AlphabetCharacter(val character: String, override var next: Grammar? = null) : Grammar {\n",
    "    override fun toString(): String = \"$character${next?.toString() ?: \"\"}\"\n",
    "}\n",
    "\n",
    "/**\n",
    " * AST node for marking a state as an accepting state\n",
    " */\n",
    "data class AcceptingState(override var next: Grammar? = null) : Grammar {\n",
    "    override fun toString(): String = \"AcceptingState${next?.toString() ?: \"\"}\"\n",
    "}\n",
    "\n",
    "/**\n",
    " * AST node for a production rule\n",
    " *\n",
    " * @property identifier the left hand side of the =, the recursive variable\n",
    " * @property rule a list of all grammar strings to use as the production rule\n",
    " */\n",
    "data class Rule(val identifier: Grammar, val rule: List<Grammar>, override var next: Grammar? = null) : Grammar {\n",
    "    override fun toString(): String = \"$identifier = ${rule.joinToString(separator = \" | \")}${\n",
    "        if (next != null) {\n",
    "            \"\\n${next.toString()}\"\n",
    "        } else {\n",
    "            \"\"\n",
    "        }\n",
    "    }\"\n",
    "}\n",
    "\n",
    "/**\n",
    " * Function to lex the inputted grammar string based on an alphabet and accepting state string into a list of tokens\n",
    " * used for parsing. This function will get the string into a more unified structure (ignoring whitespaces)\n",
    " *\n",
    " * @param input the inputted grammar string\n",
    " * @param alphabet a set of characters considered the alphabet\n",
    " * @param acceptingState the string which will be used to denote states as accepting states\n",
    " * @return list of tokens\n",
    " */\n",
    "fun lex(input: String, alphabet: Set<Char>, acceptingState: String): List<Token> {\n",
    "    return buildList {\n",
    "        var i = 0\n",
    "        while (i < input.length) {\n",
    "            val c = input[i]\n",
    "            when (c) {\n",
    "                ' ' -> {}\n",
    "                in alphabet -> add(Token(\"$c\", TokenType.AC))\n",
    "                '\\n' -> add(Token(\"\\\\n\", TokenType.NL))\n",
    "                '|' -> add(Token(\"$c\", TokenType.OR))\n",
    "                '=' -> add(Token(\"$c\", TokenType.EQ))\n",
    "                else -> {\n",
    "                    val s = buildString {\n",
    "                        append(c)\n",
    "                        i++\n",
    "                        while (i < input.length && (input[i] !in alphabet && input[i] != '\\n' && input[i] != '|' && input[i] != '=' && input[i] != ' ')) {\n",
    "                            append(input[i++])\n",
    "                        }\n",
    "                        i--\n",
    "                    }\n",
    "\n",
    "                    add(\n",
    "                        Token(\n",
    "                            s, if (s == acceptingState) {\n",
    "                                TokenType.AS\n",
    "                            } else {\n",
    "                                TokenType.ID\n",
    "                            }\n",
    "                        )\n",
    "                    )\n",
    "                }\n",
    "            }\n",
    "            i++\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/**\n",
    " * Class to hold the current parsing state\n",
    " *\n",
    " * @param tokens list of tokens to be parsed\n",
    " * @param index current token being parsed\n",
    " */\n",
    "data class ParserState(val tokens: List<Token>, val index: Int) {\n",
    "    val value: Token?\n",
    "        get() = if (index < tokens.size) {\n",
    "            tokens[index]\n",
    "        } else {\n",
    "            null\n",
    "        }\n",
    "    val nextState: ParserState\n",
    "        get() = ParserState(tokens, index + 1)\n",
    "}\n",
    "\n",
    "// Recursive Descent Parser\n",
    "\n",
    "/**\n",
    " * Handles identifiers, alphabet characters, and the accepting state marker\n",
    " *\n",
    " * atom -> identifier | alphabet_character | accepting_state\n",
    " * identifier -> non_alphabet_character\n",
    " *\n",
    " * @param state current state of the parser\n",
    " * @return the partially constructed grammar AST and updated parser state\n",
    " */\n",
    "fun atom(state: ParserState): Pair<Grammar, ParserState> {\n",
    "    var currentState = state\n",
    "    var ret: Grammar? = null\n",
    "    var curr: Grammar? = null\n",
    "\n",
    "    while ((currentState.value?.type?.equals(TokenType.ID) == true) ||\n",
    "        (currentState.value?.type?.equals(TokenType.AC) == true) ||\n",
    "        (currentState.value?.type?.equals(TokenType.AS) == true)\n",
    "    ) {\n",
    "        val value = currentState.value!!\n",
    "        when (value.type) {\n",
    "            TokenType.ID -> {\n",
    "                if (ret == null) {\n",
    "                    ret = Ident(value.value)\n",
    "                    curr = ret\n",
    "                } else {\n",
    "                    curr!!.next = Ident(value.value)\n",
    "                    curr = curr.next\n",
    "                }\n",
    "            }\n",
    "\n",
    "            TokenType.AC -> {\n",
    "                if (ret == null) {\n",
    "                    ret = AlphabetCharacter(value.value)\n",
    "                    curr = ret\n",
    "                } else {\n",
    "                    curr!!.next = AlphabetCharacter(value.value)\n",
    "                    curr = curr.next\n",
    "                }\n",
    "            }\n",
    "\n",
    "            TokenType.AS -> {\n",
    "                if (ret == null) {\n",
    "                    ret = AcceptingState()\n",
    "                    curr = ret\n",
    "                } else {\n",
    "                    curr!!.next = AcceptingState()\n",
    "                    curr = curr.next\n",
    "                }\n",
    "            }\n",
    "\n",
    "            else -> {\n",
    "                error(\"error state 1\")\n",
    "            }\n",
    "        }\n",
    "        currentState = currentState.nextState\n",
    "    }\n",
    "\n",
    "    return (ret ?: error(\"error state 2\")) to currentState\n",
    "}\n",
    "\n",
    "/**\n",
    " * Handles production rules\n",
    " *\n",
    " * Rule -> identifier '=' atom ('|' atom)*\n",
    " *\n",
    " * @param state current state of the parser\n",
    " * @return the partially constructed grammar AST and updated parser state\n",
    " */\n",
    "fun rule(state: ParserState): Pair<Grammar, ParserState> {\n",
    "    var (expr: Grammar, currentState) = atom(state)\n",
    "\n",
    "    if (currentState.value?.type?.equals(TokenType.EQ) == true) {\n",
    "        val rules = buildList {\n",
    "            do {\n",
    "                currentState = currentState.nextState\n",
    "                val (c, s) = atom(currentState)\n",
    "                add(c)\n",
    "                currentState = s\n",
    "            } while (currentState.value?.type?.equals(TokenType.OR) == true)\n",
    "        }\n",
    "        expr = Rule(expr, rule = rules)\n",
    "    }\n",
    "\n",
    "    return expr to currentState\n",
    "}\n",
    "\n",
    "/**\n",
    " * Runner function to perform the recursive descent parsing and to build the rule's vine (linked list)\n",
    " *\n",
    " * @param input list of tokens to be parsed\n",
    " * @return fully constructed grammar AST\n",
    " */\n",
    "fun parse(input: List<Token>): Grammar {\n",
    "    val state = ParserState(input, -1)\n",
    "    var ret: Grammar? = null\n",
    "    var curr: Grammar? = null\n",
    "    var currentState = state\n",
    "\n",
    "    do {\n",
    "        currentState = currentState.nextState\n",
    "        val (tr, ts) = rule(currentState)\n",
    "        currentState = ts\n",
    "        if (ret == null) {\n",
    "            ret = tr\n",
    "            curr = ret\n",
    "        } else {\n",
    "            curr!!.next = tr\n",
    "            curr = curr!!.next\n",
    "        }\n",
    "    } while (currentState.value?.type?.equals(TokenType.NL) == true)\n",
    "\n",
    "    return ret!!\n",
    "}\n",
    "\n",
    "/**\n",
    " * Class to hold NFA nodes\n",
    " *\n",
    " * @param stateID id of the specific state\n",
    " * @param transitions labelled transitions from state to state\n",
    " * @param lambdaTransitions labelled lambda transitions from state to state\n",
    " */\n",
    "data class NFANode(\n",
    "    val stateID: String,\n",
    "    val transitions: Map<String, Set<String>>,\n",
    "    val lambdaTransitions: Set<String> = setOf(),\n",
    ")\n",
    "\n",
    "/**\n",
    " * NFA structure class\n",
    " *\n",
    " * @param startState state designated as start state\n",
    " * @param acceptStates set of states designated as final states\n",
    " * @param nfaNodes map of state id to node object\n",
    " */\n",
    "class NFA(val startState: String, val acceptStates: Set<String>, val nfaNodes: Map<String, NFANode>) {\n",
    "    /**\n",
    "     * Tests if the NFA accepts the inputted string\n",
    "     *\n",
    "     * @param value the inputted string to test\n",
    "     * @return true if accepted, false if not\n",
    "     */\n",
    "    fun accepts(value: String): Boolean {\n",
    "        // set of all states to check with a cursor\n",
    "        // the cursor states where in the value string the current \"state\" is at\n",
    "        var currentStates = setOf(startState to 0)\n",
    "        // once a state's cursor exceeds the length of the inputted string, it is in a finished state\n",
    "        val finishedStates = mutableSetOf<String>()\n",
    "\n",
    "        // run the automaton until there are no states to run for\n",
    "        while (currentStates.isNotEmpty()) {\n",
    "            currentStates = buildSet {\n",
    "                for ((currentState, currentIndex) in currentStates) {\n",
    "                    // if the current cursor location is still within the string, determine the next transition\n",
    "                    // otherwise, add the string to the finish states, no more symbols can be inputted into the machine\n",
    "                    if (currentIndex < value.length) {\n",
    "                        val node = nfaNodes[currentState]!!\n",
    "                        for ((transitionString, destinationNode) in node.transitions) {\n",
    "                            if (currentIndex + transitionString.length <= value.length && value.substring(currentIndex..<currentIndex + transitionString.length) == transitionString) {\n",
    "                                destinationNode.forEach {\n",
    "                                    add(it to currentIndex + transitionString.length)\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                        addAll(node.lambdaTransitions.map { it to currentIndex })\n",
    "                    } else {\n",
    "                        finishedStates.add(currentState)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // check if any of the finished states are in the accept states\n",
    "        return finishedStates.any { it in acceptStates }\n",
    "    }\n",
    "\n",
    "    /**\n",
    "     * @return string representation of the NFA\n",
    "     */\n",
    "    override fun toString(): String {\n",
    "        return buildString {\n",
    "            append(\"Start State: ${this@NFA.startState} | Accept States: ${this@NFA.acceptStates}\")\n",
    "            append('\\n')\n",
    "            for ((lhs, node) in this@NFA.nfaNodes) {\n",
    "                append(\"    $lhs -> $node\")\n",
    "                append('\\n')\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/**\n",
    " * Converts from Grammar AST to NFA object\n",
    " *\n",
    " * @param grammar grammar to convert\n",
    " * @param startState state ID of the start state\n",
    " * @param defaultAcceptState state ID of the accept state\n",
    " * @return fully constructed NFA\n",
    " */\n",
    "fun grammar2NFA(grammar: Grammar, startState: String, defaultAcceptState: String = \"X\"): NFA {\n",
    "    // head of the grammar vine\n",
    "    var current: Grammar? = grammar\n",
    "\n",
    "    // set of all accepting states\n",
    "    val acceptingStateSet = mutableSetOf(defaultAcceptState)\n",
    "    // creation of map of state id to nfa object\n",
    "    val nfaMap = buildMap {\n",
    "        // add a default accept state to be used in certain cases [covered later]\n",
    "        put(defaultAcceptState, NFANode(defaultAcceptState, emptyMap(), emptySet()))\n",
    "\n",
    "        while (current != null) {\n",
    "            // current set of lambda transitions\n",
    "            val currentLambdaTransitions = mutableSetOf<String>()\n",
    "            // current set of labelled transitions\n",
    "            // set of nodes a transition goes to as this is an NFA\n",
    "            val currentTransitions = mutableMapOf<String, Set<String>>()\n",
    "            // current node in the vine\n",
    "            val c = current\n",
    "            // traverse to the next node in the vine\n",
    "            current = current?.next\n",
    "            when (c) {\n",
    "                // if the current node is a rule\n",
    "                is Rule -> {\n",
    "                    // checking if the left hand side of the '=' is an identifier (resolver phase)\n",
    "                    val currentState = when (val id = c.identifier) {\n",
    "                        is Ident -> id.name\n",
    "                        else -> error(\"lhs of a = must be an identifier\")\n",
    "                    }\n",
    "                    // for every grammar node in the rule\n",
    "                    for (g in c.rule) {\n",
    "                        when (g) {\n",
    "                            // set this current state as an accepting state\n",
    "                            is AcceptingState -> acceptingStateSet.add(currentState)\n",
    "                            // set this current state to have a lambda transition to the identifier\n",
    "                            is Ident -> currentLambdaTransitions.add(g.name)\n",
    "                            // construct the full alphabet multi-character transition\n",
    "                            is AlphabetCharacter -> {\n",
    "                                var currentChar: Grammar? = g\n",
    "                                var sum = \"\"\n",
    "                                while (currentChar != null) {\n",
    "                                    when (currentChar) {\n",
    "                                        // if the current character is an alphabet character, add it to the running sum\n",
    "                                        is AlphabetCharacter -> {\n",
    "                                            sum += currentChar.character\n",
    "                                            currentChar = currentChar.next\n",
    "                                            // if the next character is null, this is a terminal branch, add a transition to the default accept state to follow the right linear grammar syntax\n",
    "                                            if (currentChar == null) {\n",
    "                                                currentTransitions[sum] = currentTransitions.getOrDefault(sum, emptySet()) union setOf(defaultAcceptState)\n",
    "                                            }\n",
    "                                        }\n",
    "\n",
    "                                        // current character is an identifier\n",
    "                                        // assume this is the end of the string as the grammar parser can only handle right linear grammars\n",
    "                                        // add a transition to the identifier\n",
    "                                        is Ident -> {\n",
    "                                            currentTransitions[sum] = currentTransitions.getOrDefault(sum, emptySet()) union setOf(currentChar.name)\n",
    "                                            currentChar = currentChar.next\n",
    "                                        }\n",
    "\n",
    "                                        // rules cannot be nested\n",
    "                                        else -> error(\"cannot nest rule\")\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "\n",
    "                            // rules cannot be nested\n",
    "                            is Rule -> error(\"cannot nest rule\")\n",
    "                            else -> error(\"needed to satisfy when exhaustive checker in the kernel\")\n",
    "                        }\n",
    "                        // tie the state id to the constructed NFA object\n",
    "                        put(currentState, NFANode(currentState, currentTransitions, currentLambdaTransitions))\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                // at top level, the grammar should only be consisting of rules\n",
    "                else -> error(\"top level should be rule\")\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // given the start state, set of accepting states, and nfa map, construct the NFA object\n",
    "    return NFA(startState, acceptingStateSet, nfaMap)\n",
    "}\n",
    "\n",
    "/**\n",
    " * Helper function to enumerate over all strings in the alphabet up to a certain length\n",
    " *\n",
    " * \\forall w : w \\in L \\and |w| \\le n\n",
    " *\n",
    " * @param size max length of the string\n",
    " * @param alphabet set of all alphabet characters\n",
    " * @return sequence of all enumerated strings\n",
    " */\n",
    "fun enumerate(size: Int, alphabet: Set<Char>): Sequence<String> {\n",
    "    return sequence {\n",
    "        // memory of previous strings yielded in the enumeration\n",
    "        var prev = listOf(\"\")\n",
    "\n",
    "        // repeat until the string is the desired length\n",
    "        repeat(size) {\n",
    "            // yield the next permutation of the string with the alphabet and memoize the result to be use in the next loop\n",
    "            prev = buildList {\n",
    "                for (str in prev) {\n",
    "                    for (alphabetCharacter in alphabet) {\n",
    "                        val tmp = str + alphabetCharacter\n",
    "                        add(tmp)\n",
    "                        yield(tmp)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed Grammar\n",
      "--------------------\n",
      "S = 0S | 1A | 1B\n",
      "A = 1C\n",
      "B = 0C\n",
      "C = AcceptingState\n",
      "--------------------\n",
      "Compiled NFA\n",
      "--------------------\n",
      "Start State: S | Accept States: [X, C]\n",
      "    X -> NFANode(stateID=X, transitions={}, lambdaTransitions=[])\n",
      "    S -> NFANode(stateID=S, transitions={0=[S], 1=[A, B]}, lambdaTransitions=[])\n",
      "    A -> NFANode(stateID=A, transitions={1=[C]}, lambdaTransitions=[])\n",
      "    B -> NFANode(stateID=B, transitions={0=[C]}, lambdaTransitions=[])\n",
      "    C -> NFANode(stateID=C, transitions={}, lambdaTransitions=[])\n",
      "\n",
      "--------------------\n",
      "Accepted Strings\n",
      "--------------------\n",
      "10\n",
      "11\n",
      "010\n",
      "011\n",
      "0010\n",
      "0011\n",
      "00010\n",
      "00011\n",
      "000010\n",
      "000011\n",
      "--------------------\n",
      "Rejected Strings\n",
      "--------------------\n",
      "0\n",
      "1\n",
      "00\n",
      "01\n",
      "000\n",
      "001\n",
      "100\n",
      "101\n",
      "110\n",
      "111\n",
      "0000\n",
      "0001\n",
      "0100\n",
      "0101\n",
      "0110\n",
      "0111\n",
      "1000\n",
      "1001\n",
      "1010\n",
      "1011\n",
      "1100\n",
      "1101\n",
      "1110\n",
      "1111\n",
      "00000\n",
      "00001\n",
      "00100\n",
      "00101\n",
      "00110\n",
      "00111\n",
      "01000\n",
      "01001\n",
      "01010\n",
      "01011\n",
      "01100\n",
      "01101\n",
      "01110\n",
      "01111\n",
      "10000\n",
      "10001\n",
      "10010\n",
      "10011\n",
      "10100\n",
      "10101\n",
      "10110\n",
      "10111\n",
      "11000\n",
      "11001\n",
      "11010\n",
      "11011\n",
      "11100\n",
      "11101\n",
      "11110\n",
      "11111\n",
      "000000\n",
      "000001\n",
      "000100\n",
      "000101\n",
      "000110\n",
      "000111\n",
      "001000\n",
      "001001\n",
      "001010\n",
      "001011\n",
      "001100\n",
      "001101\n",
      "001110\n",
      "001111\n",
      "010000\n",
      "010001\n",
      "010010\n",
      "010011\n",
      "010100\n",
      "010101\n",
      "010110\n",
      "010111\n",
      "011000\n",
      "011001\n",
      "011010\n",
      "011011\n",
      "011100\n",
      "011101\n",
      "011110\n",
      "011111\n",
      "100000\n",
      "100001\n",
      "100010\n",
      "100011\n",
      "100100\n",
      "100101\n",
      "100110\n",
      "100111\n",
      "101000\n",
      "101001\n",
      "101010\n",
      "101011\n",
      "101100\n",
      "101101\n",
      "101110\n",
      "101111\n",
      "110000\n",
      "110001\n",
      "110010\n",
      "110011\n",
      "110100\n",
      "110101\n",
      "110110\n",
      "110111\n",
      "111000\n",
      "111001\n",
      "111010\n",
      "111011\n",
      "111100\n",
      "111101\n",
      "111110\n",
      "111111\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "val alphabet = setOf(\n",
    "    '0', '1'\n",
    ")\n",
    "val startState = \"S\"\n",
    "val acceptState = \"x\"\n",
    "val grammar = \"\"\"\n",
    "    S = 0S | 1A | 1B\n",
    "    A = 1C\n",
    "    B = 0C\n",
    "    C = x\n",
    "\"\"\".trimIndent()\n",
    "val n = 6\n",
    "\n",
    "val tokens = lex(grammar, alphabet, acceptState)\n",
    "val tree = parse(tokens)\n",
    "\n",
    "wrap(\"Parsed Grammar\") {\n",
    "    println(tree)\n",
    "}\n",
    "\n",
    "val nfa = grammar2NFA(tree, startState)\n",
    "\n",
    "wrap(\"Compiled NFA\") {\n",
    "    println(nfa)\n",
    "}\n",
    "\n",
    "val (accepted, rejected) = enumerate(n, alphabet).partition {\n",
    "    nfa.accepts(it)\n",
    "}\n",
    "\n",
    "wrap(\"Accepted Strings\") {\n",
    "    accepted.forEach(::println)\n",
    "}\n",
    "\n",
    "wrap(\"Rejected Strings\") {\n",
    "    rejected.forEach(::println)\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-17T23:52:28.879854Z",
     "start_time": "2023-10-17T23:52:25.955381Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.0",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
